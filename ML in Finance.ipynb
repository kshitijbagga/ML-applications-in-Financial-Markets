{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "biNKvzWhy2gJ",
    "outputId": "73abfd21-f82c-4bf8-ef7d-ade8875021c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YfJpc0_XDPa2"
   },
   "outputs": [],
   "source": [
    "model1 = tf.keras.models.load_model('LSTM_new128.h5')\n",
    "model2 = tf.keras.models.load_model('LSTM_25(128).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evnd-EoEydoU"
   },
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    df = dft.copy()\n",
    "\n",
    "    actual_close = dfact\n",
    "    pred_close = predict_func(df)\n",
    "\n",
    "    # Calculation of squared_error\n",
    "    actual_close = np.array(actual_close)\n",
    "    pred_close = np.array(pred_close)\n",
    "    mean_square_error = np.mean(np.square(actual_close-pred_close))\n",
    "\n",
    "\n",
    "    pred_prev = [df['Close'].iloc[-1]]\n",
    "    pred_prev.append(pred_close[0])\n",
    "    pred_curr = pred_close\n",
    "\n",
    "    actual_prev = [df['Close'].iloc[-1]]\n",
    "    actual_prev.append(actual_close[0])\n",
    "    actual_curr = actual_close\n",
    "\n",
    "    # Calculation of directional_accuracy\n",
    "    pred_dir = np.array(pred_curr)-np.array(pred_prev)\n",
    "    actual_dir = np.array(actual_curr)-np.array(actual_prev)\n",
    "    dir_accuracy = np.mean((pred_dir*actual_dir)>0)*100\n",
    "\n",
    "    print(f'Mean Square Error: {mean_square_error:.6f}\\nDirectional Accuracy: {dir_accuracy:.1f}')\n",
    "    return [mean_square_error, dir_accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1aopbghpywL-"
   },
   "outputs": [],
   "source": [
    "def predict_func(data):\n",
    "\n",
    "\n",
    "    # data['Close'].fillna(-9999, inplace=True)\n",
    "    # na_indices = data['Close'].index[data['Close'] == -9999]\n",
    "\n",
    "    # for i in na_indices:\n",
    "    #     data['Close'][i] = data['Close'][i-1]/2 + data['Close'][i+1]/2\n",
    "\n",
    "\n",
    "    i=0\n",
    "\n",
    "    while( pd.isna(data.at[i,'Close']) ):\n",
    "        i=i+1\n",
    "\n",
    "    # do backfilling till first non- null index as interpolation can't be done\n",
    "    mask = data.index <= i\n",
    "    data_filled = data.copy()\n",
    "    data_filled.loc[mask] = data_filled.loc[mask].fillna(method='backfill')\n",
    "    data=data_filled\n",
    "\n",
    "    data=data.interpolate()\n",
    "\n",
    "    df=data['Close']\n",
    "    # df.interpolate(method=\"linear\")\n",
    "\n",
    "    df=np.array(df)\n",
    "    # print(df)\n",
    "    df=np.reshape(df,(50, 1))\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    df = scaler.fit_transform(df)\n",
    "    df=np.reshape(df,(1, 50, 1))\n",
    "\n",
    "    predicted_1=model2.predict(df)\n",
    "    predicted_1=np.array(predicted_1)\n",
    "\n",
    "    df=np.reshape(df,(50, 1))\n",
    "    df=np.append(df, predicted_1)\n",
    "\n",
    "    df=np.reshape(df,(1, 51, 1))\n",
    "\n",
    "\n",
    "    predicted_2=model2.predict(df[:,1:,:])\n",
    "    predicted_2=np.array(predicted_2)\n",
    "\n",
    "    # print(predicted_1)\n",
    "    # print(predicted_2)\n",
    "\n",
    "    df=np.reshape(df,(51,1))\n",
    "    df=np.append(df, predicted_2)\n",
    "\n",
    "    df=np.reshape(df,(52,1))\n",
    "    df=scaler.inverse_transform(df)\n",
    "\n",
    "    # print(df)\n",
    "\n",
    "    return [df[-2][0], df[-1][0]]\n",
    "    # return [0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__== \"__main__\":\n",
    "    result=evaluate()\n",
    "    print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YuRYY5z2jen2"
   },
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8IU2xf9SZFR_",
    "outputId": "86d7f0bc-edbc-46fb-a5cd-4cb1859af2a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2570    11930.34961\n",
       "2571    11767.75000\n",
       "Name: Close, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('STOCK_INDEX.csv')\n",
    "len = 150\n",
    "dftata=df[len-50:len]\n",
    "dfact = df[\"Close\"][len:len+2]\n",
    "dfact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__== \"__main__\":\n",
    "    data = pd.read_csv('STOCK_INDEX.csv')\n",
    "\n",
    "    # df = yf.Ticker(\"NESTLEIND.NS\")\n",
    "    # Valid options are 1d, 5d, 1mo, 3mo, 6mo, 1y,\n",
    "    # 2y, 5y, 10y and ytd.\n",
    "    # df = df.history(period=\"5y\")\n",
    "    sum_rmse=0\n",
    "    sum_acc=0\n",
    "    for i in range(2400, 2600):\n",
    "        dft=data[i-50:i]\n",
    "        dfact=data['Close'][i:i+2]\n",
    "        mean=np.mean(dft[\"Close\"])\n",
    "        evaluate()\n",
    "    #   rmse=(res[0]**0.5)/mean\n",
    "    #   print(rmse*100)\n",
    "    #   dir_acc=res[1]\n",
    "    #   sum_rmse+=rmse\n",
    "    #   sum_acc+=dir_acc\n",
    "\n",
    "    # length = 651\n",
    "    # sum_rmse=sum_rmse/length\n",
    "    # sum_acc=sum_acc/length\n",
    "    # print(sum_rmse)\n",
    "    # print(sum_acc)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
